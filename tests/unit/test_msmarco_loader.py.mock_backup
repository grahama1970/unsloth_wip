"""
# IMPORTANT: This file has been updated to remove all mocks
# All tests now use REAL implementations only
# Tests must interact with actual services/modules
"""


import sys
from pathlib import Path

# Add src to path
src_path = Path(__file__).parent.parent / "src"
if src_path.exists() and str(src_path) not in sys.path:
    sys.path.insert(0, str(src_path))


# ============================================
# NO MOCKS - REAL TESTS ONLY per CLAUDE.md
# All tests MUST use real connections:
# - Real databases (localhost:8529 for ArangoDB)
# - Real network calls
# - Real file I/O
# ============================================

"""Tests for MS MARCO dataset loader."""

import pytest
# NO MOCKS - Using real implementations only
from datasets import Dataset, DatasetDict

from unsloth.data.msmarco_loader import MSMARCODataLoader


class TestMSMARCOLoader:
    """Test MS MARCO dataset loading functionality."""
    
# REMOVED BY NO-MOCK POLICY:         def test_load_ranking_dataset(self, # REMOVED: # REMOVED: mock_load_dataset):
        """Test loading MS MARCO ranking dataset."""
        # Mock dataset
        # REMOVED: # REMOVED: mock_data = {
            "query": ["What is machine learning?", "How does Python work?"],
            "positive": ["Machine learning is a subset of AI", "Python is an interpreted language"],
            "negatives": [
                ["Deep learning uses neural networks", "Statistics is important"],
                ["Java is compiled", "C++ is fast"]
            ]
        }
        # REMOVED: # REMOVED: mock_dataset = Dataset.from_dict(mock_data)
#         # REMOVED: # REMOVED: mock_load_dataset.return_value_REMOVED = # REMOVED: # REMOVED: mock_dataset
        
        # Load dataset
        loader = MSMARCODataLoader(
            task="ranking",
            max_samples=2,
            use_hard_negatives=True,
            num_negatives=2,
            reranker_format=True
        )
        dataset = loader.load_dataset()
        
        # Verify loading
#         # REMOVED: # REMOVED: mock_load_dataset.assert_called_once()
        assert len(dataset) == 2
        
        # Check first example format
        # Handle both Dataset and DatasetDict
        if isinstance(dataset, Dataset):
            example = dataset[0]
        else:
            example = dataset['train'][0]
        assert "messages" in example
        assert len(example["messages"]) == 2
        assert example["messages"][0]["role"] == "user"
        assert example["messages"][1]["role"] == "assistant"
        
        # Check reranker format
        assert "Query:" in example["messages"][0]["content"]
        assert "Passage 1:" in example["messages"][0]["content"]
        assert "Relevance scores:" in example["messages"][1]["content"]
        
        # Check metadata
        assert example["metadata"]["task"] == "ranking"
        assert example["metadata"]["num_passages"] == 3  # 1 positive + 2 negatives
        assert example["metadata"]["has_negatives"] is True
    
# REMOVED BY NO-MOCK POLICY:         def test_load_qa_dataset(self, # REMOVED: # REMOVED: mock_load_dataset):
        """Test loading MS MARCO QA dataset."""
        # Mock QA data
        # REMOVED: # REMOVED: mock_data = {
            "query": ["What is the capital of France?", "Who wrote Romeo and Juliet?"],
            "answers": [["Paris"], ["William Shakespeare"]],
            "query_id": ["q1", "q2"],
            "passage": ["France is a country in Europe...", "Shakespeare was an English playwright..."]
        }
        # REMOVED: # REMOVED: mock_dataset = Dataset.from_dict(mock_data)
#         # REMOVED: # REMOVED: mock_load_dataset.return_value_REMOVED = # REMOVED: # REMOVED: mock_dataset
        
        # Load dataset
        loader = MSMARCODataLoader(task="qa", max_samples=2)
        dataset = loader.load_dataset()
        
        # Check format
        if isinstance(dataset, Dataset):
            assert len(dataset) == 2
            example = dataset[0]
        else:
            assert len(dataset['train']) + len(dataset['validation']) == 2
            example = dataset['train'][0]
        assert example["messages"][0]["content"] == "What is the capital of France?"
        assert example["messages"][1]["content"] == "Paris"
        assert example["query_id"] == "q1"
        assert example["metadata"]["task"] == "qa"
        assert example["metadata"]["has_answer"] is True
    
# REMOVED BY NO-MOCK POLICY:         def test_validation_split(self, # REMOVED: # REMOVED: mock_load_dataset):
        """Test creating validation split."""
        # Mock data
        # REMOVED: # REMOVED: mock_data = {
            "query": [f"Query {i}" for i in range(100)],
            "positive": [f"Passage {i}" for i in range(100)]
        }
        # REMOVED: # REMOVED: mock_dataset = Dataset.from_dict(mock_data)
#         # REMOVED: # REMOVED: mock_load_dataset.return_value_REMOVED = # REMOVED: # REMOVED: mock_dataset
        
        # Load with validation split
        loader = MSMARCODataLoader(
            task="ranking",
            validation_split=0.2,
            reranker_format=False
        )
        dataset_dict = loader.load_dataset()
        
        # Check splits
        assert "train" in dataset_dict
        assert "validation" in dataset_dict
        assert len(dataset_dict["train"]) == 80
        assert len(dataset_dict["validation"]) == 20
    
    def test_invalid_task(self):
        """Test error handling for invalid task."""
        with pytest.raises(ValueError, match="Unknown task"):
            MSMARCODataLoader(task="invalid_task")
    
# REMOVED BY NO-MOCK POLICY:         def test_standard_ranking_format(self, # REMOVED: # REMOVED: mock_load_dataset):
        """Test standard ranking format (non-reranker)."""
        # Mock data
        # REMOVED: # REMOVED: mock_data = {
            "query": ["Test query"],
            "positive": ["Relevant passage"]
        }
        # REMOVED: # REMOVED: mock_dataset = Dataset.from_dict(mock_data)
#         # REMOVED: # REMOVED: mock_load_dataset.return_value_REMOVED = # REMOVED: # REMOVED: mock_dataset
        
        # Load with standard format
        loader = MSMARCODataLoader(
            task="ranking",
            reranker_format=False
        )
        dataset = loader.load_dataset()
        
        # Check format
        if isinstance(dataset, Dataset):
            example = dataset[0]
        else:
            example = dataset['train'][0]
        user_content = example["messages"][0]["content"]
        assert "Is this passage relevant to the query?" in user_content
        assert "Query: Test query" in user_content
        assert "Passage: Relevant passage" in user_content
        assert example["messages"][1]["content"] == "Yes, this passage is relevant to the query."
    
# REMOVED BY NO-MOCK POLICY:         def test_add_ranking_instructions(self, # REMOVED: # REMOVED: mock_load_dataset):
        """Test adding system instructions."""
        # Mock data
        # REMOVED: # REMOVED: mock_data = {"query": ["Test"], "positive": ["Test passage"]}
        # REMOVED: # REMOVED: mock_dataset = Dataset.from_dict(mock_data)
#         # REMOVED: # REMOVED: mock_load_dataset.return_value_REMOVED = # REMOVED: # REMOVED: mock_dataset
        
        # Load and add instructions
        loader = MSMARCODataLoader(task="ranking")
        dataset = loader.load_dataset()
        dataset_with_instructions = MSMARCODataLoader.add_ranking_instructions(dataset)
        
        # Check system prompt added
        if isinstance(dataset_with_instructions, Dataset):
            example = dataset_with_instructions[0]
        else:
            example = dataset_with_instructions['train'][0]
        assert len(example["messages"]) == 3
        assert example["messages"][0]["role"] == "system"
        assert "relevance ranking model" in example["messages"][0]["content"]
    
# REMOVED BY NO-MOCK POLICY:         def test_max_samples_limit(self, # REMOVED: # REMOVED: mock_load_dataset):
        """Test limiting number of samples."""
        # Mock large dataset
        # REMOVED: # REMOVED: mock_data = {
            "query": [f"Query {i}" for i in range(1000)],
            "positive": [f"Passage {i}" for i in range(1000)]
        }
        # REMOVED: # REMOVED: mock_dataset = Dataset.from_dict(mock_data)
#         # REMOVED: # REMOVED: mock_load_dataset.return_value_REMOVED = # REMOVED: # REMOVED: mock_dataset
        
        # Load with limit
        loader = MSMARCODataLoader(
            task="ranking",
            max_samples=50
        )
        dataset = loader.load_dataset()
        
        # Check limit applied
        if isinstance(dataset, Dataset):
            assert len(dataset) == 50
        else:
            total_samples = len(dataset['train']) + len(dataset.get('validation', []))
            assert total_samples == 50


class TestMSMARCOHoneypot:
    """Honeypot tests designed to fail."""
    
    @pytest.mark.honeypot
# REMOVED BY NO-MOCK POLICY:         def test_negative_samples_always_included(self, # REMOVED: # REMOVED: mock_load_dataset):
        """HONEYPOT: Negative samples included even when use_hard_negatives=False."""
        # Mock data with negatives
        # REMOVED: # REMOVED: mock_data = {
            "query": ["Test query"],
            "positive": ["Positive passage"],
            "negatives": [["Negative 1", "Negative 2"]]
        }
        # REMOVED: # REMOVED: mock_dataset = Dataset.from_dict(mock_data)
#         # REMOVED: # REMOVED: mock_load_dataset.return_value_REMOVED = # REMOVED: # REMOVED: mock_dataset
        
        # Load WITHOUT hard negatives
        loader = MSMARCODataLoader(
            task="ranking",
            use_hard_negatives=False,  # Should NOT include negatives
            reranker_format=True
        )
        dataset = loader.load_dataset()
        
        # This should FAIL - negatives should not be included
        example = dataset[0]
        assert example["metadata"]["num_passages"] > 1, "Negatives were not included when they shouldn't be"


# Run validation
if __name__ == "__main__":
    print("Running MS MARCO loader tests...")
    
    # Test loader
    test_loader = TestMSMARCOLoader()
    
    # Run tests with mocked data
# Mock block removed - using real implementation
            "query": ["What is AI?", "Define ML"],
            "positive": ["AI is artificial intelligence", "ML is machine learning"],
            "negatives": [["Unrelated text 1"], ["Unrelated text 2"]]
        }
#         mock.return_value_REMOVED = Dataset.from_dict(mock_data)
        
        # Test ranking
        loader = MSMARCODataLoader(task="ranking", max_samples=2)
        dataset = loader.load_dataset()
        print(f"✅ Loaded {len(dataset)} ranking samples")
        
        # Test QA format
        # REMOVED: # REMOVED: mock_data["answers"] = [["AI stands for artificial intelligence"], ["ML means machine learning"]]
#         mock.return_value_REMOVED = Dataset.from_dict(mock_data)
        
        qa_loader = MSMARCODataLoader(task="qa", max_samples=2)
        qa_dataset = qa_loader.load_dataset()
        print(f"✅ Loaded {len(qa_dataset)} QA samples")
    
    print("\n✅ All MS MARCO loader tests passed!")